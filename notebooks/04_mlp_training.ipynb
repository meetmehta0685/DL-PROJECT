{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3efb9f83",
   "metadata": {},
   "source": [
    "# MLP Training on Extracted Features\n",
    "\n",
    "This notebook loads precomputed feature vectors and trains a small MLP classifier. It tracks metrics and saves the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1587ef27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ebf4a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature files found.\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "repo_root = Path('..').resolve()\n",
    "feature_dir = Path('.')\n",
    "\n",
    "train_feat_path = feature_dir / 'train_features.npy'\n",
    "val_feat_path = feature_dir / 'val_features.npy'\n",
    "train_lbl_path = feature_dir / 'train_labels.npy'\n",
    "val_lbl_path = feature_dir / 'val_labels.npy'\n",
    "\n",
    "for p in [train_feat_path, val_feat_path, train_lbl_path, val_lbl_path]:\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f'Missing file: {p.resolve()}')\n",
    "\n",
    "print('Feature files found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da18eff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features: (5216, 512)\n",
      "Val features: (16, 512)\n",
      "Train labels: (5216,)\n",
      "Val labels: (16,)\n"
     ]
    }
   ],
   "source": [
    "# Load features and labels\n",
    "train_features = np.load(train_feat_path)\n",
    "val_features = np.load(val_feat_path)\n",
    "train_labels = np.load(train_lbl_path)\n",
    "val_labels = np.load(val_lbl_path)\n",
    "\n",
    "print('Train features:', train_features.shape)\n",
    "print('Val features:', val_features.shape)\n",
    "print('Train labels:', train_labels.shape)\n",
    "print('Val labels:', val_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94bb0377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 82 | Val batches: 1\n"
     ]
    }
   ],
   "source": [
    "# Dataloaders\n",
    "batch_size = 64\n",
    "train_ds = TensorDataset(\n",
    "    torch.from_numpy(train_features).float(),\n",
    "    torch.from_numpy(train_labels).long()\n",
    ")\n",
    "val_ds = TensorDataset(\n",
    "    torch.from_numpy(val_features).float(),\n",
    "    torch.from_numpy(val_labels).long()\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f'Train batches: {len(train_loader)} | Val batches: {len(val_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c757c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.2, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# MLP model\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=512, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MLPClassifier(input_dim=train_features.shape[1]).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "print(model)\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0374ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss: 0.6000 Acc: 0.7402 | Val Loss: 0.8829 Acc: 0.5000\n",
      "Saved best model to /Users/meetmehta/Desktop/project/DL Project/pneumonia-detection/notebooks/best_mlp_model.pt\n",
      "Epoch 02 | Train Loss: 0.5872 Acc: 0.7429 | Val Loss: 0.8029 Acc: 0.5000\n",
      "Saved best model to /Users/meetmehta/Desktop/project/DL Project/pneumonia-detection/notebooks/best_mlp_model.pt\n",
      "Epoch 03 | Train Loss: 0.5598 Acc: 0.7429 | Val Loss: 0.7443 Acc: 0.5000\n",
      "Saved best model to /Users/meetmehta/Desktop/project/DL Project/pneumonia-detection/notebooks/best_mlp_model.pt\n",
      "Epoch 04 | Train Loss: 0.4796 Acc: 0.7692 | Val Loss: 0.5854 Acc: 0.5625\n",
      "Saved best model to /Users/meetmehta/Desktop/project/DL Project/pneumonia-detection/notebooks/best_mlp_model.pt\n",
      "Epoch 05 | Train Loss: 0.4186 Acc: 0.8160 | Val Loss: 1.0973 Acc: 0.5625\n",
      "Epoch 06 | Train Loss: 0.3678 Acc: 0.8422 | Val Loss: 1.1265 Acc: 0.5625\n",
      "Epoch 07 | Train Loss: 0.3651 Acc: 0.8395 | Val Loss: 0.8203 Acc: 0.5625\n",
      "Epoch 08 | Train Loss: 0.3724 Acc: 0.8370 | Val Loss: 0.9868 Acc: 0.5625\n",
      "Epoch 09 | Train Loss: 0.3791 Acc: 0.8173 | Val Loss: 1.2642 Acc: 0.5000\n",
      "Epoch 10 | Train Loss: 0.3684 Acc: 0.8173 | Val Loss: 0.8235 Acc: 0.5625\n",
      "Epoch 11 | Train Loss: 0.3812 Acc: 0.8194 | Val Loss: 1.3668 Acc: 0.5625\n",
      "Epoch 12 | Train Loss: 0.4189 Acc: 0.8073 | Val Loss: 0.9008 Acc: 0.5000\n",
      "Epoch 13 | Train Loss: 0.3824 Acc: 0.8340 | Val Loss: 0.9564 Acc: 0.5625\n",
      "Epoch 14 | Train Loss: 0.3812 Acc: 0.8265 | Val Loss: 1.0938 Acc: 0.5625\n",
      "Epoch 15 | Train Loss: 0.3691 Acc: 0.8378 | Val Loss: 1.0057 Acc: 0.5625\n",
      "Epoch 16 | Train Loss: 0.3307 Acc: 0.8487 | Val Loss: 1.2814 Acc: 0.5000\n",
      "Epoch 17 | Train Loss: 0.3215 Acc: 0.8558 | Val Loss: 1.4689 Acc: 0.5625\n",
      "Epoch 18 | Train Loss: 0.3169 Acc: 0.8505 | Val Loss: 1.1361 Acc: 0.5000\n",
      "Epoch 19 | Train Loss: 0.3220 Acc: 0.8464 | Val Loss: 1.1748 Acc: 0.5625\n",
      "Epoch 20 | Train Loss: 0.3180 Acc: 0.8478 | Val Loss: 1.5340 Acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Training loop with metric tracking\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            total_loss += loss.item() * x.size(0)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += x.size(0)\n",
    "    avg_loss = total_loss / total\n",
    "    acc = correct / total\n",
    "    return avg_loss, acc\n",
    "\n",
    "num_epochs = 20\n",
    "best_val_loss = float('inf')\n",
    "best_path = Path('best_mlp_model.pt')\n",
    "\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': []\n",
    "}\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x, y in train_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * x.size(0)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += x.size(0)\n",
    "\n",
    "    train_loss = running_loss / total\n",
    "    train_acc = correct / total\n",
    "    val_loss, val_acc = evaluate(model, val_loader)\n",
    "\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "\n",
    "    print(f'Epoch {epoch:02d} | Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'input_dim': train_features.shape[1],\n",
    "            'num_classes': 2\n",
    "        }, best_path)\n",
    "        print(f'Saved best model to {best_path.resolve()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
